{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/pickem/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pbp.model import LlamaForCausalLM\n",
    "from pbp.config import PBPConfig, parse_yaml_to_config\n",
    "\n",
    "config = parse_yaml_to_config(\"config.yaml\")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\"pickem/best_model\", config=config)\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# load infer.pkl\n",
    "with open(\"infer.pkl\", \"rb\") as f:\n",
    "    infer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44697/3013937646.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  teams = (torch.tensor(infer[\"home_embedding\"]).to(\"cuda\"), torch.tensor(infer[\"away_embedding\"]).to(\"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(infer[\"input_ids\"]).to(\"cuda\")\n",
    "teams = (torch.tensor(infer[\"home_embedding\"]).to(\"cuda\"), torch.tensor(infer[\"away_embedding\"]).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch_size to input_ids\n",
    "input_ids = input_ids.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids=input_ids, team_embeddings=teams, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5,   7, 183,  23,   8,  26,  10,  27,   9,  27,   9, 101,  98, 101,\n",
       "          26, 101,   9, 101, 101, 101, 101, 101, 101, 101,   9,  26, 101, 101,\n",
       "         101,  10,  27,  27,   9,   9, 101,  99,  26, 101, 101,   9, 101, 101,\n",
       "         101,  26, 101,  10,  27,   9,   9,  27,   9, 101,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"pickem_tokenizer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[GAME_START] [ODDS_START] 30 7 [ODDS_END] : & @ [PLAY_SEP] @ [PLAY_SEP] 00 Q1 00 : 00 [PLAY_SEP] 00 00 00 00 00 00 00 [PLAY_SEP] : 00 00 00 & @ @ [PLAY_SEP] [PLAY_SEP] 00 Q3 : 00 00 [PLAY_SEP] 00 00 00 : 00 & @ [PLAY_SEP] [PLAY_SEP] @ [PLAY_SEP] 00 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
